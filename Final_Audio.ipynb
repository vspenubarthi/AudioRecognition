{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import librosa\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from microphone import record_audio\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion \n",
    "from scipy.ndimage.morphology import iterate_structure\n",
    "import pickle\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_digital(*file_path_or_music):\n",
    "    if(len(file_path_or_music)!= 0):\n",
    "        if(\".mp3\" in file_path_or_music[0]):\n",
    "            #analyze file input if it is there\n",
    "            from pathlib import Path\n",
    "            local_song_path = Path(file_path_or_music[0])\n",
    "            frames, sample_rate = librosa.load(local_song_path, sr=44100, mono=True, duration=5) #Seconds\n",
    "            audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "        else:\n",
    "            #analyze file input if it is there\n",
    "            with open(file_path_or_music[0], 'r') as R:\n",
    "            # each sample is written to a single line in the text file\n",
    "            # this reads them in as a single integer-valued numpy array\n",
    "                audio_data = np.asarray([int(i) for i in R])\n",
    "    else:\n",
    "        #or else we are recording what they say\n",
    "        from microphone import record_audio\n",
    "        listen_time = 5  # seconds\n",
    "        frames, sample_rate = record_audio(listen_time)\n",
    "        # read in the recorded audio, saved as a numpy array of 16-bit integers\n",
    "        audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "        Checking=True\n",
    "    return audio_data, Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitalToSpecto(audio):\n",
    "    S, freqs, times = mlab.specgram(audio, NFFT=4096, Fs=44100,\n",
    "                                  window=mlab.window_hanning,\n",
    "                                  noverlap=4096 // 2)\n",
    "    return(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_to_peaks(arr):\n",
    "    \"\"\" \n",
    "    Creates a boolean array showing peaks, given data from a spectrogram.\n",
    "    \n",
    "    Parameters:\n",
    "        arr: The array produced by the spectrogram from digital_to_spectrogram with shape (N,M)\n",
    "        \n",
    "    Returns:\n",
    "        peaks: A boolean array with shape (N,M). Peaks in the data are where peaks == True.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating the histogram\n",
    "    arr_flattened = np.log(arr.flatten() + 1e-20)\n",
    "    \n",
    "    N = arr_flattened.size # Number of elements in the array\n",
    "    cnt, bin_edges = np.histogram(arr_flattened, bins=N//200, density=True)\n",
    "    bin_width = np.diff(bin_edges) \n",
    "    \n",
    "    ## print(np.sum(cnt*bin_width)) # check that summation = 1\n",
    "    \n",
    "    # Creating the cumulative distribution\n",
    "    cumulative_distr = np.cumsum(cnt*bin_width)\n",
    "    \n",
    "    # Defining the cutoff\n",
    "    frac_cut = 0.9\n",
    "    bin_index_of_cutoff = np.searchsorted(cumulative_distr, frac_cut)\n",
    "    \n",
    "    # given the bin-index, we want the associated log-amplitude value for that bin\n",
    "    cutoff_log_amplitude = bin_edges[bin_index_of_cutoff]\n",
    "    \n",
    "    # Defining the footprint\n",
    "    fp = generate_binary_structure(rank=2,connectivity=2)\n",
    "    \n",
    "    peaks = ((arr > cutoff_log_amplitude) & (arr == maximum_filter(arr, footprint=fp)))\n",
    "    freq, time = np.where(peaks)\n",
    "    print(freq)\n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_to_dic_newsongs(local_peaks):\n",
    "    with open(\"songs.pkl\", mode=\"rb\") as opened_file:\n",
    "        song_dic = pickle.load(opened_file)\n",
    "    freq, time= np.where(local_peaks)\n",
    "    song_name=input(\"Song Name= \")\n",
    "    for i in range(len(local_peaks)-15):\n",
    "        j=1\n",
    "        while j<16:\n",
    "            finger=(freq[i], freq[i+j], time[j]-time[i])\n",
    "            j+=1\n",
    "            song_dir=(song_name, time[i])\n",
    "            song_dic.update([(finger, song_dir)])\n",
    "    print(song_dic)\n",
    "    # open and save to a pkl file, mode = wb for binary storage w/ numpy array\n",
    "    with open(\"songs.pkl\", mode=\"wb\") as opened_file:\n",
    "        pickle.dump(song_dic, opened_file)\n",
    "    print(\"Done\")\n",
    "    return \"Done\"\n",
    "\n",
    "#ideas for optimization:::::::::::::::::::::\n",
    "# vstack with tuple inside it (the fingerprint)\n",
    "# convert that into a list of tuples using a zip function and the map function and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_to_dic_findsong(local_peaks):\n",
    "    with open(\"songs.pkl\", mode=\"rb\") as opened_file:\n",
    "        song_dic2 = pickle.load(opened_file)\n",
    "    freq, time= np.where(local_peaks)\n",
    "    songList = []\n",
    "    fingerList=[]\n",
    "    for i in range(len(local_peaks)-15):\n",
    "        j=1\n",
    "        for j in range(16):\n",
    "            finger=(freq[i], freq[i+j], time[i+j]-time[i])\n",
    "            fingerList.append(finger)\n",
    "            if finger in song_dic2:\n",
    "                song_guess=song_dic2[finger]\n",
    "                songList.append((song_guess[0], (song_guess[1]-finger[2])))\n",
    "                Counter_songs= Counter(songList)\n",
    "    song=Counter_songs.most_common(1)\n",
    "    with open(\"songs.pkl\", mode=\"wb\") as opened_file:\n",
    "        pickle.dump(song_dic2, opened_file)\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_function(song):\n",
    "    Checking=False\n",
    "    audio=audio_to_digital(song)\n",
    "    arr=digitalToSpecto(audio)\n",
    "    local_peaks=spectrogram_to_peaks(arr)\n",
    "    if Checking==True:\n",
    "        Checking=False\n",
    "        \n",
    "    else:\n",
    "        peaks_to_dic_newsongs(local_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
