{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib\n",
    "import librosa\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from microphone import record_audio\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "from scipy.ndimage.filters import maximum_filter\n",
    "from scipy.ndimage.morphology import generate_binary_structure, binary_erosion \n",
    "from scipy.ndimage.morphology import iterate_structure\n",
    "import pickle\n",
    "from collections import Counter, defaultdict\n",
    "# make this a glboal variable - it is false unless audio_to_digital changes\n",
    "Checking=False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_digital(*file_path_or_music):\n",
    "    if(len(file_path_or_music)!= 0):\n",
    "        Checking=False\n",
    "        if(\".mp3\" in file_path_or_music[0]):\n",
    "            #analyze file input if it is there\n",
    "            from pathlib import Path\n",
    "            local_song_path = Path(file_path_or_music[0])\n",
    "            frames, sample_rate = librosa.load(local_song_path, sr=44100, mono=True, duration=5) #Seconds\n",
    "            audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "\n",
    "        else:\n",
    "            #analyze file input if it is there\n",
    "            with open(file_path_or_music[0], 'r') as R:\n",
    "            # each sample is written to a single line in the text file\n",
    "            # this reads them in as a single integer-valued numpy array\n",
    "                audio_data = np.asarray([int(i) for i in R])\n",
    "    else:\n",
    "        #or else we are recording what they say\n",
    "        from microphone import record_audio\n",
    "        listen_time = 5  # seconds\n",
    "        frames, sample_rate = record_audio(listen_time)\n",
    "        # read in the recorded audio, saved as a numpy array of 16-bit integers\n",
    "        audio_data = np.hstack([np.frombuffer(i, np.int16) for i in frames])\n",
    "        Checking=True\n",
    "    return audio_data, Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def digitalToSpecto(audio):\n",
    "    S, freqs, times = mlab.specgram(audio, NFFT=4096, Fs=44100,\n",
    "                                  window=mlab.window_hanning,\n",
    "                                  noverlap=4096 // 2)\n",
    "    return(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectrogram_to_peaks(arr):\n",
    "    \"\"\" \n",
    "    Creates a boolean array showing peaks, given data from a spectrogram.\n",
    "    \n",
    "    Parameters:\n",
    "        arr: The array produced by the spectrogram from digital_to_spectrogram with shape (N,M)\n",
    "        \n",
    "    Returns:\n",
    "        peaks: A boolean array with shape (N,M). Peaks in the data are where peaks == True.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating the histogram\n",
    "    arr_flattened = np.log(arr.flatten() + 1e-20)\n",
    "    \n",
    "    N = arr_flattened.size # Number of elements in the array\n",
    "    cnt, bin_edges = np.histogram(arr_flattened, bins=N//200, density=True)\n",
    "    bin_width = np.diff(bin_edges) \n",
    "    \n",
    "    ## print(np.sum(cnt*bin_width)) # check that summation = 1\n",
    "    \n",
    "    # Creating the cumulative distribution\n",
    "    cumulative_distr = np.cumsum(cnt*bin_width)\n",
    "    \n",
    "    # Defining the cutoff\n",
    "    frac_cut = 0.9\n",
    "    bin_index_of_cutoff = np.searchsorted(cumulative_distr, frac_cut)\n",
    "    \n",
    "    # given the bin-index, we want the associated log-amplitude value for that bin\n",
    "    cutoff_log_amplitude = bin_edges[bin_index_of_cutoff]\n",
    "    \n",
    "    # Defining the footprint\n",
    "    fp = generate_binary_structure(rank=2,connectivity=2)\n",
    "    fp = np.ones((4,5))\n",
    "    \n",
    "    peaks = ((arr > cutoff_log_amplitude) & (arr == maximum_filter(arr, footprint=fp)))\n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peaks_to_dic_newsongs(local_peaks):\n",
    "    with open(\"songs.pkl\", mode=\"rb\") as opened_file:\n",
    "        song_dic = pickle.load(opened_file)\n",
    "    time,freq= np.where(local_peaks)\n",
    "    song_name=input(\"Song Name= \")\n",
    "    fanout = 15\n",
    "    song_dic = defaultdict(list)\n",
    "    for i in range(freq.size-fanout):\n",
    "        for j in range(1,fanout+1):\n",
    "            finger=(freq[i], freq[i+j], time[i+j]-time[i])\n",
    "            song_dir=[song_name, time[i]]\n",
    "            if finger in song_dic:\n",
    "                previousfingers=song_dic[finger]\n",
    "                previousfingers.append(song_dir)\n",
    "                song_dic.update([(finger, previousfingers)])\n",
    "            else:\n",
    "                song_dic.update([(finger, song_dir)])\n",
    "    # open and save to a pkl file, mode = wb for binary storage w/ numpy array\n",
    "    with open(\"songs.pkl\", mode=\"wb\") as opened_file:\n",
    "        pickle.dump(song_dic, opened_file)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "with open(\"songs.pkl\", mode=\"wb\") as opened_file:\n",
    "        pickle.dump({}, opened_file)\n",
    "with open(\"songs.pkl\", mode=\"rb\") as opened_file:\n",
    "    song_dic = pickle.load(opened_file)\n",
    "print(song_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def peaks_to_dic_findsong(local_peaks):\n",
    "    with open(\"songs.pkl\", mode=\"rb\") as opened_file:\n",
    "        song_dic2 = pickle.load(opened_file)\n",
    "    time, freq= np.where(local_peaks)\n",
    "    songList = []\n",
    "    fingerList=[]\n",
    "    abs_time=[]\n",
    "    fanout=15\n",
    "    for i in range(freq.size-fanout):\n",
    "        for j in range(1,fanout+1):\n",
    "            finger=(freq[i], freq[i+j], time[i+j]-time[i])\n",
    "            abs_time.append(time[i])\n",
    "            fingerList.append(finger)\n",
    "    for i in range(len(fingerList)):\n",
    "        if fingerList[i] in song_dic2:\n",
    "            song_guess=song_dic2[fingerList[i]]\n",
    "            for t in range(len(song_guess)):\n",
    "                songList.append((song_guess[t][0], (song_guess[t][1]-abs_time[i])))\n",
    "    Counter_songs= Counter(songList)\n",
    "    song=Counter_songs.most_common(1) \n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_function(*song):\n",
    "    if(len(song)!=0):\n",
    "        audio, Checking=audio_to_digital(song[0])\n",
    "        arr=digitalToSpecto(audio)\n",
    "        local_peaks=spectrogram_to_peaks(arr)\n",
    "        if Checking==True:\n",
    "            Checking=False\n",
    "            return peaks_to_dic_findsong(local_peaks)\n",
    "        else:\n",
    "            peaks_to_dic_newsongs(local_peaks)\n",
    "    else:\n",
    "        audio, Checking=audio_to_digital()\n",
    "        arr=digitalToSpecto(audio)\n",
    "        local_peaks=spectrogram_to_peaks(arr)\n",
    "        if Checking==True:\n",
    "            Checking=False\n",
    "            return peaks_to_dic_findsong(local_peaks)\n",
    "        else:\n",
    "            peaks_to_dic_newsongs(local_peaks)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input device 'Internal Microphone (Conexant S'\n",
      "Recording ended\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types dtype('<U21') dtype('<U21') dtype('<U21')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-1cda77d5fd2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfinal_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-0cca14e8620e>\u001b[0m in \u001b[0;36mfinal_function\u001b[1;34m(*song)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mChecking\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mChecking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpeaks_to_dic_findsong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_peaks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mpeaks_to_dic_newsongs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_peaks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-45-9bb48980de93>\u001b[0m in \u001b[0;36mpeaks_to_dic_findsong\u001b[1;34m(local_peaks)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0msong_guess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msong_dic2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfingerList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_guess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                 \u001b[0msongList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msong_guess\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mabs_time\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mCounter_songs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msongList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msong\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCounter_songs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types dtype('<U21') dtype('<U21') dtype('<U21')"
     ]
    }
   ],
   "source": [
    "final_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
